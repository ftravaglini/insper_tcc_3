{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "791f0e12-bbb6-4bcb-8a2e-1048ab03bbd2",
   "metadata": {},
   "source": [
    "# NLP # Text classification - Bag of Word - course Lazy - NPL Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a418dd8-90ca-41b5-b4ea-9638598d471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe3dc47-89e5-458d-8f30-888115f929ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d116ad26-12a3-487c-9b47-5f9abe2b6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copom = pd.read_csv('df_copom_label_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e853d8-e066-46f9-bac5-f3686a143845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ = df_copom[df_copom['type'] == 'statement'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0403aab-6e78-44c6-ba1d-cd2324d077f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>meeting_number</th>\n",
       "      <th>date_x</th>\n",
       "      <th>date_y</th>\n",
       "      <th>selic</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_txt</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_words</th>\n",
       "      <th>text_raw</th>\n",
       "      <th>num_words_raw</th>\n",
       "      <th>label_hawk_dove</th>\n",
       "      <th>label_next_meet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>2006/03/08</td>\n",
       "      <td>2006/03/08</td>\n",
       "      <td>16.5</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>decrease</td>\n",
       "      <td>statement</td>\n",
       "      <td>march meeting , banco central brasil 's moneta...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>In the March Meeting, the Banco Central do Br...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>dovish</td>\n",
       "      <td>decrease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  meeting_number      date_x      date_y  selic  decision  \\\n",
       "0           0             117  2006/03/08  2006/03/08   16.5     -0.75   \n",
       "\n",
       "  decision_txt       type                                               text  \\\n",
       "0     decrease  statement  march meeting , banco central brasil 's moneta...   \n",
       "\n",
       "   num_words                                           text_raw  \\\n",
       "0       55.0   In the March Meeting, the Banco Central do Br...   \n",
       "\n",
       "   num_words_raw label_hawk_dove label_next_meet  \n",
       "0           67.0          dovish        decrease  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copom.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c84c4022-78cd-4e0e-aa03-61e3ef9a1bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8698e7ff-84f9-4ddd-9026-8f2254ec0e55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "meeting_number     0\n",
       "date_x             0\n",
       "date_y             0\n",
       "selic              0\n",
       "decision           0\n",
       "decision_txt       0\n",
       "type               0\n",
       "text               0\n",
       "num_words          0\n",
       "text_raw           0\n",
       "num_words_raw      0\n",
       "label_hawk_dove    2\n",
       "label_next_meet    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copom.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ba11b6-93be-4204-9bb2-b7b82bc8d221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_copom.dropna().copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b7fede1-deb1-4b11-945b-9c7b5a9aa244",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "meeting_number     0\n",
       "date_x             0\n",
       "date_y             0\n",
       "selic              0\n",
       "decision           0\n",
       "decision_txt       0\n",
       "type               0\n",
       "text               0\n",
       "num_words          0\n",
       "text_raw           0\n",
       "num_words_raw      0\n",
       "label_hawk_dove    0\n",
       "label_next_meet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "070945dc-0e3e-4704-a3aa-8103c818f61b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df['text'].copy()\n",
    "y = df['label_hawk_dove'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46cda136-9131-4755-8f43-af2d199a59ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       dovish\n",
       "1       dovish\n",
       "2       dovish\n",
       "3       dovish\n",
       "4       dovish\n",
       "        ...   \n",
       "156    neutral\n",
       "157    neutral\n",
       "158    neutral\n",
       "159    neutral\n",
       "160    neutral\n",
       "Name: label_hawk_dove, Length: 161, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1086ea9f-132f-4961-b909-095032ea8a96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Perform train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e66071af-502d-4cf6-b3ec-911caf938ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a85667d-98c5-429d-8fdc-fffd8c4e2fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55c29d86-73f7-4c24-a207-fe56f302bc0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02344f75-55f8-49ef-99a4-69c2d3cdf38a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GloveVectorizer:\n",
    "  def __init__(self):\n",
    "    # load in pre-trained word vectors\n",
    "    print('Loading in word vectors...')\n",
    "    word2vec = {}\n",
    "    embedding = []\n",
    "    idx2word = []\n",
    "    with open('glove.6B/glove.6B.300d.txt', encoding='utf-8') as f:\n",
    "      # is just a space-separated text file in the format:\n",
    "      # word vec[0] vec[1] vec[2] ...\n",
    "      for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "        embedding.append(vec)\n",
    "        idx2word.append(word)\n",
    "    print('Found %s word vectors.' % len(word2vec))\n",
    "\n",
    "    # save for later\n",
    "    self.word2vec = word2vec\n",
    "    self.embedding = np.array(embedding)\n",
    "    self.word2idx = {v:k for k,v in enumerate(idx2word)}\n",
    "    self.V, self.D = self.embedding.shape\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.lower().split()\n",
    "      vecs = []\n",
    "      for word in tokens:\n",
    "        if word in self.word2vec:\n",
    "          vec = self.word2vec[word]\n",
    "          vecs.append(vec)\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1762919f-5d5b-4994-ae12-aad1696f2a08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Word2VecVectorizer:\n",
    "  def __init__(self):\n",
    "    print(\"Loading in word vectors...\")\n",
    "    self.word_vectors = KeyedVectors.load_word2vec_format(\n",
    "      'GoogleNews-vectors-negative300.bin',\n",
    "      binary=True\n",
    "    )\n",
    "    print(\"Finished loading in word vectors\")\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    # determine the dimensionality of vectors\n",
    "    v = self.word_vectors.get_vector('king')\n",
    "    self.D = v.shape[0]\n",
    "\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.split()\n",
    "      vecs = []\n",
    "      m = 0\n",
    "      for word in tokens:\n",
    "        try:\n",
    "          # throws KeyError if word not found\n",
    "          vec = self.word_vectors.get_vector(word)\n",
    "          vecs.append(vec)\n",
    "          m += 1\n",
    "        except KeyError:\n",
    "          pass\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e2f705f-fcd5-4b36-9bc1-2ce8586088b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Found 400000 word vectors.\n",
      "Numer of samples with no words found: 0 / 128\n",
      "Numer of samples with no words found: 0 / 33\n"
     ]
    }
   ],
   "source": [
    "vectorizer = GloveVectorizer()\n",
    "\n",
    "X_train_glo = vectorizer.fit_transform(X_train)\n",
    "y_train_glo = y_train\n",
    "\n",
    "X_test_glo = vectorizer.transform(X_test)\n",
    "y_test_glo = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70f5c293-d800-4c98-a474-7464e2bf7e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 1.0\n",
      "test score: 0.7575757575757576\n"
     ]
    }
   ],
   "source": [
    "# create the model, train it, print scores\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(X_train_glo, y_train_glo)\n",
    "print(\"train score:\", model.score(X_train_glo, y_train_glo))\n",
    "print(\"test score:\", model.score(X_test_glo, y_test_glo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a736ed4-0519-4586-9d4a-68ed0f429821",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 0 / 128\n",
      "Numer of samples with no words found: 0 / 33\n"
     ]
    }
   ],
   "source": [
    "vectorizer = Word2VecVectorizer()\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "y_train_vec = y_train\n",
    "\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "y_test_vec = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "703a34a2-2bb3-441e-96d0-6982019529f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 1.0\n",
      "test score: 0.7575757575757576\n"
     ]
    }
   ],
   "source": [
    "# create the model, train it, print scores\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(X_train_vec, y_train_vec)\n",
    "print(\"train score:\", model.score(X_train_vec, y_train_vec))\n",
    "print(\"test score:\", model.score(X_test_vec, y_test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7167b612-3e61-494b-8305-787829955fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "248e8ed9-371b-48ce-8855-c1b322776d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.796875\n",
      "test score: 0.7575757575757576\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(X_train_vec, y_train_vec)\n",
    "print(\"train score:\", model.score(X_train_vec, y_train_vec))\n",
    "print(\"test score:\", model.score(X_test_vec, y_test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7793b-a72d-4005-9efb-1e0a8d037cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
