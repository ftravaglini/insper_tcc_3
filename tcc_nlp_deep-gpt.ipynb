{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "791f0e12-bbb6-4bcb-8a2e-1048ab03bbd2",
   "metadata": {},
   "source": [
    "# Deep: NLP With Transformer -  GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a418dd8-90ca-41b5-b4ea-9638598d471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d116ad26-12a3-487c-9b47-5f9abe2b6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copom = pd.read_csv('df_copom_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60443267-16fc-4610-9633-d96d57c5a6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Selic</th>\n",
       "      <th>Meeting_Number</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Decision_txt</th>\n",
       "      <th>label_hawk_dove</th>\n",
       "      <th>label_next_meet</th>\n",
       "      <th>Text</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006/03/08</td>\n",
       "      <td>16.50</td>\n",
       "      <td>117.0</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>decrease</td>\n",
       "      <td>dovish</td>\n",
       "      <td>decrease</td>\n",
       "      <td>In the March Meeting, the Banco Central do Br...</td>\n",
       "      <td>Statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006/04/19</td>\n",
       "      <td>15.75</td>\n",
       "      <td>118.0</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>decrease</td>\n",
       "      <td>dovish</td>\n",
       "      <td>decrease</td>\n",
       "      <td>In the April Meeting, the Monetary Policy Com...</td>\n",
       "      <td>Statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006/05/31</td>\n",
       "      <td>15.25</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>decrease</td>\n",
       "      <td>dovish</td>\n",
       "      <td>decrease</td>\n",
       "      <td>In the May Meeting, the Monetary Policy Commi...</td>\n",
       "      <td>Statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006/07/19</td>\n",
       "      <td>14.75</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>decrease</td>\n",
       "      <td>dovish</td>\n",
       "      <td>decrease</td>\n",
       "      <td>In the July Meeting, the Copom unanimously de...</td>\n",
       "      <td>Statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006/08/30</td>\n",
       "      <td>14.25</td>\n",
       "      <td>121.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>decrease</td>\n",
       "      <td>dovish</td>\n",
       "      <td>decrease</td>\n",
       "      <td>In the August Meeting, the Copom unanimously ...</td>\n",
       "      <td>Statement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Selic  Meeting_Number  Decision Decision_txt label_hawk_dove  \\\n",
       "0  2006/03/08  16.50           117.0     -0.75     decrease          dovish   \n",
       "1  2006/04/19  15.75           118.0     -0.75     decrease          dovish   \n",
       "2  2006/05/31  15.25           119.0     -0.50     decrease          dovish   \n",
       "3  2006/07/19  14.75           120.0     -0.50     decrease          dovish   \n",
       "4  2006/08/30  14.25           121.0     -0.50     decrease          dovish   \n",
       "\n",
       "  label_next_meet                                               Text  \\\n",
       "0        decrease   In the March Meeting, the Banco Central do Br...   \n",
       "1        decrease   In the April Meeting, the Monetary Policy Com...   \n",
       "2        decrease   In the May Meeting, the Monetary Policy Commi...   \n",
       "3        decrease   In the July Meeting, the Copom unanimously de...   \n",
       "4        decrease   In the August Meeting, the Copom unanimously ...   \n",
       "\n",
       "        Type  \n",
       "0  Statement  \n",
       "1  Statement  \n",
       "2  Statement  \n",
       "3  Statement  \n",
       "4  Statement  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac0fc1c1-4d8e-4c01-9497-21f92b78583e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                                                      2009/10/21\n",
       "Selic                                                           8.75\n",
       "Meeting_Number                                                   146\n",
       "Decision                                                           0\n",
       "Decision_txt                                                 mantain\n",
       "label_hawk_dove                                              neutral\n",
       "label_next_meet                                              mantain\n",
       "Text                  \\tBrasÃ­lia - In light of inflation prospect...\n",
       "Type                                                       Statement\n",
       "Name: 29, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copom.iloc[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e594a921-8058-4fff-b65d-78f9e59b6c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copom.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c44e4b-0795-4f05-838d-c5caa6b9dcd9",
   "metadata": {},
   "source": [
    "### Split test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9783a43e-78d9-4a51-a65e-58e9ba6bf0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ftrav\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\sklearn\\utils\\validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9572834-9d66-4da3-8e55-e6fa9177a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_copom.copy()\n",
    "y = df_copom['label_hawk_dove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26356f49-54c3-4096-bf3d-4154aacce342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48226f65-b901-44e2-b066-bdc45a9dda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = X_train['Text'].tolist()\n",
    "labels = y_train.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "505cec28-3d87-47e6-a8a5-c7acfaea9efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beac442e-643e-4e33-a3d7-3dfaa0cd436e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8a8b86c-9391-4baf-9aff-59221bb3faa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 512 # number of the tokens tokenizer will create\n",
    "num_samples = len (texts)\n",
    "num_samples, seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7029bbf4-2632-4984-8d0a-42bdc2382cdd",
   "metadata": {},
   "source": [
    "#### Convert labels to one-hot encoded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b0e070e-a8ae-43f6-b8b1-504ec31b12c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_classes = list(set(labels))\n",
    "num_classes = len(label_classes)\n",
    "\n",
    "label_to_index = {label: index for index, label in enumerate(label_classes)}\n",
    "index_to_label = {index: label for label, index in label_to_index.items()}\n",
    "\n",
    "labels_encoded = np.array([label_to_index[label] for label in labels])\n",
    "labels = np.eye(num_classes)[labels_encoded]\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1721ff2-87dd-43b3-b557-f8676830f4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff51f9-f286-4f63-b42e-1ee6dc4ae8ca",
   "metadata": {},
   "source": [
    "## ChatCPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d2a1951-6484-4aae-8b6a-2b778d3c405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6743208-3a17-40c6-8174-0826b1d5b0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define the BERT model\n",
    "model_name = 'bert-base-uncased'\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67112a67-f569-4014-a6d2-b337c63904f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2006e288-883c-4136-bc68-1dd8e12733d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class CentralBankDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29f2a1c4-2d66-4d91-9ade-75829de93d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = CentralBankDataset(texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0ca2c75-230c-46df-b74a-470d82610cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the texts and create data loader\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return inputs, torch.tensor(labels)\n",
    "\n",
    "batch_size = 2\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b58aeb56-c220-41c4-8704-1b2ca4711c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "epochs = 5\n",
    "learning_rate = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4a7270a-1981-4f5f-b2a6-55d81911487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer and scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(dataloader) * epochs\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03604f41-6cc0-4358-96f3-f707fb916b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ftrav\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Average Loss: 0.6516\n",
      "Epoch 2/5, Average Loss: 0.6131\n",
      "Epoch 3/5, Average Loss: 0.5453\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c01a6f-c4f6-4ab1-a2e7-74520eb5c18c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4013bfe8-7127-482d-8abd-d683bcf30b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "496c018b-79b1-4cdc-b92b-afd599a5d552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # for i, text in enumerate(test_texts):\n",
    "    for i, row in X_test.iterrows():\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            row['Text']    ,\n",
    "            padding='longest',\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        outputs = model(**inputs)\n",
    "        print(np.argmax(outputs.logits[0].cpu().numpy()))\n",
    "        X_test.at[i, 'Sentiment'] = np.argmax(outputs.logits[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "816fab87-33d9-423d-abdf-736b715fcf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Selic</th>\n",
       "      <th>Meeting_Number</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Decision_txt</th>\n",
       "      <th>label_hawk_dove</th>\n",
       "      <th>label_next_meet</th>\n",
       "      <th>Text</th>\n",
       "      <th>Type</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2016/03/02</td>\n",
       "      <td>14.25</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>mantain</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mantain</td>\n",
       "      <td>The Copom released the following note to the ...</td>\n",
       "      <td>Statement</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2023/03/22</td>\n",
       "      <td>13.75</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>mantain</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mantain</td>\n",
       "      <td>A) Update of economic outlook and Copomâs scen...</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2021/06/16</td>\n",
       "      <td>4.25</td>\n",
       "      <td>239.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>increase</td>\n",
       "      <td>hawkish</td>\n",
       "      <td>increase</td>\n",
       "      <td>A) Update of economic outlook and Copomâs base...</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2013/04/17</td>\n",
       "      <td>7.50</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>increase</td>\n",
       "      <td>hawkish</td>\n",
       "      <td>increase</td>\n",
       "      <td>The Copom released the following note to the ...</td>\n",
       "      <td>Statement</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2018/03/21</td>\n",
       "      <td>6.50</td>\n",
       "      <td>213.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>decrease</td>\n",
       "      <td>dovish</td>\n",
       "      <td>mantain</td>\n",
       "      <td>The Copom unanimously decided to reduce the Se...</td>\n",
       "      <td>Statement</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2009/10/21</td>\n",
       "      <td>8.75</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>mantain</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mantain</td>\n",
       "      <td>\\tBrasÃ­lia - In light of inflation prospect...</td>\n",
       "      <td>Statement</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2022/09/21</td>\n",
       "      <td>13.75</td>\n",
       "      <td>249.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>mantain</td>\n",
       "      <td>dovish</td>\n",
       "      <td>mantain</td>\n",
       "      <td>A) Update of economic outlook and Copomâs scen...</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2012/10/10</td>\n",
       "      <td>7.25</td>\n",
       "      <td>170.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>decrease</td>\n",
       "      <td>dovish</td>\n",
       "      <td>mantain</td>\n",
       "      <td>The Copom released the following note to the ...</td>\n",
       "      <td>Statement</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2018/09/19</td>\n",
       "      <td>6.50</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>mantain</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mantain</td>\n",
       "      <td>âThe Copom unanimously decided to maintain the...</td>\n",
       "      <td>Statement</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2022/05/04</td>\n",
       "      <td>12.75</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>increase</td>\n",
       "      <td>hawkish</td>\n",
       "      <td>increase</td>\n",
       "      <td>âIn its 246th meeting, the Copom unanimously d...</td>\n",
       "      <td>Statement</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2008/07/23</td>\n",
       "      <td>13.00</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>increase</td>\n",
       "      <td>hawkish</td>\n",
       "      <td>increase</td>\n",
       "      <td>\\t\"BrasÃ­lia - Assessing the macroeconomic ou...</td>\n",
       "      <td>Statement</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2013/11/27</td>\n",
       "      <td>10.00</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>increase</td>\n",
       "      <td>hawkish</td>\n",
       "      <td>increase</td>\n",
       "      <td>The Copom released the following note to the ...</td>\n",
       "      <td>Statement</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2008/01/23</td>\n",
       "      <td>11.25</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>mantain</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mantain</td>\n",
       "      <td>Assessing the macroeconomic outlook and the p...</td>\n",
       "      <td>Statement</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2014/07/16</td>\n",
       "      <td>11.00</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>mantain</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mantain</td>\n",
       "      <td>The Copom released the following note to the ...</td>\n",
       "      <td>Statement</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2009/03/11</td>\n",
       "      <td>11.25</td>\n",
       "      <td>141.0</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>decrease</td>\n",
       "      <td>dovish</td>\n",
       "      <td>decrease</td>\n",
       "      <td>\\t\"BrasÃ­lia - Assessing the macroeconomic o...</td>\n",
       "      <td>Statement</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2009/12/09</td>\n",
       "      <td>8.75</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>mantain</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mantain</td>\n",
       "      <td>\\tBrasÃ­lia - In light of inflation prospects...</td>\n",
       "      <td>Statement</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Selic  Meeting_Number  Decision Decision_txt label_hawk_dove  \\\n",
       "78   2016/03/02  14.25           197.0      0.00      mantain         neutral   \n",
       "155  2023/03/22  13.75           253.0      0.00      mantain         neutral   \n",
       "128  2021/06/16   4.25           239.0      0.75     increase         hawkish   \n",
       "55   2013/04/17   7.50           174.0      0.25     increase         hawkish   \n",
       "94   2018/03/21   6.50           213.0     -0.25     decrease          dovish   \n",
       "29   2009/10/21   8.75           146.0      0.00      mantain         neutral   \n",
       "147  2022/09/21  13.75           249.0      0.00      mantain          dovish   \n",
       "51   2012/10/10   7.25           170.0     -0.25     decrease          dovish   \n",
       "98   2018/09/19   6.50           217.0      0.00      mantain         neutral   \n",
       "141  2022/05/04  12.75           246.0      1.00     increase         hawkish   \n",
       "19   2008/07/23  13.00           136.0      0.75     increase         hawkish   \n",
       "60   2013/11/27  10.00           179.0      0.50     increase         hawkish   \n",
       "15   2008/01/23  11.25           132.0      0.00      mantain         neutral   \n",
       "65   2014/07/16  11.00           184.0      0.00      mantain         neutral   \n",
       "24   2009/03/11  11.25           141.0     -1.50     decrease          dovish   \n",
       "30   2009/12/09   8.75           147.0      0.00      mantain         neutral   \n",
       "\n",
       "    label_next_meet                                               Text  \\\n",
       "78          mantain   The Copom released the following note to the ...   \n",
       "155         mantain  A) Update of economic outlook and Copomâs scen...   \n",
       "128        increase  A) Update of economic outlook and Copomâs base...   \n",
       "55         increase   The Copom released the following note to the ...   \n",
       "94          mantain  The Copom unanimously decided to reduce the Se...   \n",
       "29          mantain     \\tBrasÃ­lia - In light of inflation prospect...   \n",
       "147         mantain  A) Update of economic outlook and Copomâs scen...   \n",
       "51          mantain   The Copom released the following note to the ...   \n",
       "98          mantain  âThe Copom unanimously decided to maintain the...   \n",
       "141        increase  âIn its 246th meeting, the Copom unanimously d...   \n",
       "19         increase    \\t\"BrasÃ­lia - Assessing the macroeconomic ou...   \n",
       "60         increase   The Copom released the following note to the ...   \n",
       "15          mantain   Assessing the macroeconomic outlook and the p...   \n",
       "65          mantain   The Copom released the following note to the ...   \n",
       "24         decrease     \\t\"BrasÃ­lia - Assessing the macroeconomic o...   \n",
       "30          mantain    \\tBrasÃ­lia - In light of inflation prospects...   \n",
       "\n",
       "          Type  Sentiment  \n",
       "78   Statement        0.0  \n",
       "155    Minutes        0.0  \n",
       "128    Minutes        0.0  \n",
       "55   Statement        0.0  \n",
       "94   Statement        0.0  \n",
       "29   Statement        0.0  \n",
       "147    Minutes        0.0  \n",
       "51   Statement        0.0  \n",
       "98   Statement        0.0  \n",
       "141  Statement        0.0  \n",
       "19   Statement        0.0  \n",
       "60   Statement        0.0  \n",
       "15   Statement        0.0  \n",
       "65   Statement        0.0  \n",
       "24   Statement        0.0  \n",
       "30   Statement        0.0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d528a9c-0978-448c-8dd8-466e20ce23c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
