{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "791f0e12-bbb6-4bcb-8a2e-1048ab03bbd2",
   "metadata": {},
   "source": [
    "# SVM-chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a418dd8-90ca-41b5-b4ea-9638598d471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d116ad26-12a3-487c-9b47-5f9abe2b6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copom = pd.read_csv('df_copom_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60443267-16fc-4610-9633-d96d57c5a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_copom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac0fc1c1-4d8e-4c01-9497-21f92b78583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_copom.iloc[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e594a921-8058-4fff-b65d-78f9e59b6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_copom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49aa719b-43ed-48ee-b71c-8a18bf99210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_copom['Text'].tolist()\n",
    "labels = df_copom['label_hawk_dove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d452f22-49aa-4b70-96aa-7d948efc4336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ftrav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ftrav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "215d3c9b-2970-41e4-803a-011606d1d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd9153e5-deaa-414d-95d0-fe5fbe925dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data and extract labels\n",
    "preprocessed_text = []\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    preprocessed_text.append(preprocess_text(text))\n",
    "\n",
    "labels = df_copom['label_hawk_dove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2013b576-3f97-46e6-8bbb-9ef0b3614444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_text, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e033fb79-6697-4a83-b6b3-680012a34b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature extraction using TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_features = vectorizer.fit_transform(X_train)\n",
    "X_test_features = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c26cba28-5bda-4948-ad0d-bf2e975fdb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train an SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e955998b-3542-496c-8eb8-f33da57a5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for the test set\n",
    "y_pred = svm_classifier.predict(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c922543a-9ea4-4151-b364-e6bd36d6791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      dovish       0.80      0.67      0.73         6\n",
      "     hawkish       0.79      0.92      0.85        12\n",
      "     neutral       0.85      0.79      0.81        14\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        32\n",
      "   macro avg       0.81      0.79      0.80        32\n",
      "weighted avg       0.81      0.81      0.81        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f19a7f79-38d9-4186-96a6-34bd0115ea3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  1  1]\n",
      " [ 0 11  1]\n",
      " [ 1  2 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38f6ec75-ab33-4bcb-bd16-a2a8d75b53fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac703ff-a9cb-4104-970b-84be177e533f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
