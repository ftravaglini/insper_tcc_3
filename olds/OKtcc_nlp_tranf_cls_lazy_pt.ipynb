{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "791f0e12-bbb6-4bcb-8a2e-1048ab03bbd2",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a418dd8-90ca-41b5-b4ea-9638598d471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d116ad26-12a3-487c-9b47-5f9abe2b6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copom = pd.read_csv('df_copom_label_pt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60443267-16fc-4610-9633-d96d57c5a6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meeting_number</th>\n",
       "      <th>date_x</th>\n",
       "      <th>date_y</th>\n",
       "      <th>selic</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_txt</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_words</th>\n",
       "      <th>text_raw</th>\n",
       "      <th>num_words_raw</th>\n",
       "      <th>label_hawk_dove</th>\n",
       "      <th>label_next_meet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>1998/01/28</td>\n",
       "      <td>1998/01/28</td>\n",
       "      <td>34.5</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>cortar</td>\n",
       "      <td>minutes</td>\n",
       "      <td>sumáriopreços nível atividade agregados monetá...</td>\n",
       "      <td>3926.0</td>\n",
       "      <td>\\nSumárioPreços e Nível de Atividade\\nAgregado...</td>\n",
       "      <td>5066.0</td>\n",
       "      <td>dovish</td>\n",
       "      <td>cortar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meeting_number      date_x      date_y  selic  decision decision_txt  \\\n",
       "0              21  1998/01/28  1998/01/28   34.5      -3.5       cortar   \n",
       "\n",
       "      type                                               text  num_words  \\\n",
       "0  minutes  sumáriopreços nível atividade agregados monetá...     3926.0   \n",
       "\n",
       "                                            text_raw  num_words_raw  \\\n",
       "0  \\nSumárioPreços e Nível de Atividade\\nAgregado...         5066.0   \n",
       "\n",
       "  label_hawk_dove label_next_meet  \n",
       "0          dovish          cortar  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copom.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e853d8-e066-46f9-bac5-f3686a143845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_copom[(df_copom['type'] == 'statement') & (df_copom['num_words'] <= 410)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0403aab-6e78-44c6-ba1d-cd2324d077f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meeting_number</th>\n",
       "      <th>date_x</th>\n",
       "      <th>date_y</th>\n",
       "      <th>selic</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_txt</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_words</th>\n",
       "      <th>text_raw</th>\n",
       "      <th>num_words_raw</th>\n",
       "      <th>label_hawk_dove</th>\n",
       "      <th>label_next_meet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>205</td>\n",
       "      <td>2017/02/22</td>\n",
       "      <td>2017/02/22</td>\n",
       "      <td>12.25</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>cortar</td>\n",
       "      <td>statement</td>\n",
       "      <td>​o copom decidiu , por unanimidade , reduzir t...</td>\n",
       "      <td>350.0</td>\n",
       "      <td>​O Copom decidiu, por unanimidade, reduzir a t...</td>\n",
       "      <td>527.0</td>\n",
       "      <td>dovish</td>\n",
       "      <td>cortar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     meeting_number      date_x      date_y  selic  decision decision_txt  \\\n",
       "338             205  2017/02/22  2017/02/22  12.25     -0.75       cortar   \n",
       "\n",
       "          type                                               text  num_words  \\\n",
       "338  statement  ​o copom decidiu , por unanimidade , reduzir t...      350.0   \n",
       "\n",
       "                                              text_raw  num_words_raw  \\\n",
       "338  ​O Copom decidiu, por unanimidade, reduzir a t...          527.0   \n",
       "\n",
       "    label_hawk_dove label_next_meet  \n",
       "338          dovish          cortar  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eb2b82d-e34c-4f81-aec7-b7a8987d10d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 51.,  15.,  29.,  23.,  17.,   2.,  12.,  19.,  21.,  18.,  28.,\n",
       "        22.,  55.,  25.,  26.,  14.,  16.,  20.,  34.,  44.,  42.,  31.,\n",
       "        24.,  33.,  45.,  35.,  38.,  27.,  30.,  61.,  80.,  53.,  46.,\n",
       "        60.,  58.,  40.,  43.,  52.,  36.,  69.,  73.,  78.,  49.,  32.,\n",
       "        47.,  66.,  90.,  37.,  70., 218.,  57.,  41., 102., 109., 103.,\n",
       "       122., 126., 125.,  48.,  86.,  99.,  98., 260., 405., 350.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_['num_words'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c84c4022-78cd-4e0e-aa03-61e3ef9a1bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4207fd03-91db-4c89-bacf-92cdbef7fc69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_['label_hawk_dove'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84e19871-b405-48bf-a136-441609657027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_map = {'dovish': 0, 'neutral': 1, 'hawkish': 2}\n",
    "df_['target'] = df_['label_hawk_dove'].map(target_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8869383-6d9e-43fc-9b6c-fffcb62eb2e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_[['text', 'target']]\n",
    "df.columns = ['sentence', 'label']\n",
    "df.to_csv('data_copom_transf_en.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90657d76-9557-498d-8653-ac7c404c7086",
   "metadata": {},
   "source": [
    "#### Convert to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01d14340-a2e5-4f38-a2d3-dbbac8911a64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ftrav\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/ftrav/.cache/huggingface/datasets/csv/default-d41efd73b821a35c/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "Extracting data files: 100%|████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 199.99it/s]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/ftrav/.cache/huggingface/datasets/csv/default-d41efd73b821a35c/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 111.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_dataset = load_dataset('csv', data_files='data_copom_transf_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "516ab7be-ef65-4b11-a61c-4186da0bd307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 157\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c44e4b-0795-4f05-838d-c5caa6b9dcd9",
   "metadata": {},
   "source": [
    "#### Split test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "095e63a6-deb5-46d1-ac39-885c86bfe228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = raw_dataset['train'].train_test_split(test_size=0.2, seed=2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2e58e4a-1f38-42f5-9ee4-ab40562b5c71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 125\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 32\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff51f9-f286-4f63-b42e-1ee6dc4ae8ca",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e2ac12f-92d4-4663-b0d8-fd758eb718fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"poltextlab/xlm-roberta-large-portuguese-cap\")\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"poltextlab/xlm-roberta-large-portuguese-cap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd9153e5-deaa-414d-95d0-fe5fbe925dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'poltextlab/xlm-roberta-large-portuguese-cap'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be909174-068b-4879-89d1-2e1cd23d37b9",
   "metadata": {},
   "source": [
    "#### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "708d931c-f000-4bd0-a7d0-fd4745e1dc33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abe79af4-de28-4046-b5c6-795283421950",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████| 616/616 [00:00<?, ?B/s]\n",
      "C:\\Users\\ftrav\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ftrav\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)tencepiece.bpe.model: 100%|████████████████████████████████████████| 5.07M/5.07M [00:00<00:00, 8.63MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|████████████████████████████████████████| 9.10M/9.10M [00:00<00:00, 12.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ffaf227-5f80-4f04-b016-ad0edf67e123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['sentence'], truncation=True, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef275b04-2bdc-42b6-b977-232d93e56c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\ftrav\\.cache\\huggingface\\datasets\\csv\\default-d41efd73b821a35c\\0.0.0\\eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d\\cache-b7e57aa89bcd48fd.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = split.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241abab3-3614-4325-925b-021aeafd7055",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01320179-b486-4077-8a9f-16a1bd03f8a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification,  Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "87f4ac5c-9ffe-4533-a89e-4a4d5b92f203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at poltextlab/xlm-roberta-large-portuguese-cap and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([22, 1024]) in the checkpoint and torch.Size([3, 1024]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([22]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint,\n",
    "                                                           num_labels=3,\n",
    "                                                           problem_type=\"multi_label_classification\",\n",
    "                                                           ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e8488a3-a365-4db5-a400-e0a0699f0ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c06e7fac-7f9f-4c23-8cbc-ddb6eec92651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "XLMRobertaForSequenceClassification                               --\n",
       "├─XLMRobertaModel: 1-1                                            --\n",
       "│    └─XLMRobertaEmbeddings: 2-1                                  --\n",
       "│    │    └─Embedding: 3-1                                        256,002,048\n",
       "│    │    └─Embedding: 3-2                                        526,336\n",
       "│    │    └─Embedding: 3-3                                        1,024\n",
       "│    │    └─LayerNorm: 3-4                                        2,048\n",
       "│    │    └─Dropout: 3-5                                          --\n",
       "│    └─XLMRobertaEncoder: 2-2                                     --\n",
       "│    │    └─ModuleList: 3-6                                       302,309,376\n",
       "├─XLMRobertaClassificationHead: 1-2                               --\n",
       "│    └─Linear: 2-3                                                1,049,600\n",
       "│    └─Dropout: 2-4                                               --\n",
       "│    └─Linear: 2-5                                                3,075\n",
       "==========================================================================================\n",
       "Total params: 559,893,507\n",
       "Trainable params: 559,893,507\n",
       "Non-trainable params: 0\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a0e98ae-ab04-42f9-aca1-5a49ad56e424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(logits_and_labels):\n",
    "    logits, labels = logits_and_labels\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = np.mean(predictions == labels)\n",
    "    f1 = f1_score(labels, predictions, average='macro')\n",
    "    return {'accuracy': acc, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "66ddafee-eacd-4637-a7b9-1304d9208585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir='training_dir',\n",
    "#     evaluation_strategy='epoch',\n",
    "#     save_strategy='epoch',\n",
    "#     num_train_epochs=3,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0e82dea-a02e-4ce9-b880-97315d3f5c46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='training_dir',\n",
    "    logging_dir='training_dir',\n",
    "    logging_strategy='epoch',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-06,\n",
    "    seed=42,\n",
    "    save_strategy='epoch',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c8a57c4-f80f-4347-a2b6-c87d433eb048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "39888059-a41b-41dc-b9ce-38c67d93ac56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([8])) must be the same as input size (torch.Size([8, 3]))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\transformers\\trainer.py:1645\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1640\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1642\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1644\u001b[0m )\n\u001b[1;32m-> 1645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1646\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   1647\u001b[0m     resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   1648\u001b[0m     trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   1649\u001b[0m     ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   1650\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\transformers\\trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1935\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   1937\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1938\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1941\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1942\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1943\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1944\u001b[0m ):\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1946\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\transformers\\trainer.py:2759\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2758\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2759\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[0;32m   2761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2762\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\transformers\\trainer.py:2784\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2782\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2783\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2784\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   2785\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2786\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1509\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1510\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:1263\u001b[0m, in \u001b[0;36mXLMRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1262\u001b[0m         loss_fct \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss()\n\u001b[1;32m-> 1263\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_fct(logits, labels)\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[0;32m   1266\u001b[0m     output \u001b[38;5;241m=\u001b[39m (logits,) \u001b[38;5;241m+\u001b[39m outputs[\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1509\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1510\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:725\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target,\n\u001b[0;32m    726\u001b[0m                                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    727\u001b[0m                                               pos_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_weight,\n\u001b[0;32m    728\u001b[0m                                               reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\torch\\nn\\functional.py:3201\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   3198\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[1;32m-> 3201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m   3203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[1;31mValueError\u001b[0m: Target size (torch.Size([8])) must be the same as input size (torch.Size([8, 3]))"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c96c66-718f-4d6b-8b3d-6d81f8bb1a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!dir training_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e54b8-52ac-4da7-a694-d341e2e3d9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08da70f-72ae-436c-b0f3-041e326e2bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "savedmodel = pipeline('text-classification',\n",
    "                      model='training_dir/checkpoint-50',\n",
    "                      device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715754d4-cd7d-4d61-975d-92ad49e71b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f8d15-6fe6-427b-a95d-0315be003fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_pred = savedmodel(split['test']['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606dfa0-d709-4879-8217-709ca8e19a45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8537ea-5009-4a31-9467-123026384990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split['test']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddaa43f-06fb-46bf-9c9e-6f95d5cf785b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_label(d):\n",
    "    return int(d['label'].split('_')[1])\n",
    "\n",
    "test_pred = [get_label(d) for d in test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a50c0-69e6-440f-a849-f1cf91f032c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"acc:\", accuracy_score(split['test']['label'], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4447305-0e85-4267-a2ce-87867711658f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"f1:\", f1_score(split['test']['label'], test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c866b-ebf0-4da1-8fb7-4a652442c72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scikit-Learn is transitioning to V1 but it's not available on Colab\n",
    "# The changes modify how confusion matrices are plotted\n",
    "def plot_cm(cm):\n",
    "    classes = ['dovish', 'neutral', 'hawkish']\n",
    "    df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "    ax = sn.heatmap(df_cm, annot=True, fmt='g')\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Target\")\n",
    "\n",
    "cm = confusion_matrix(split['test']['label'], test_pred, normalize='true')\n",
    "plot_cm(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a645fc-0661-40d7-ae7b-0f9f04bc8286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03768b35-c4a3-44be-b00e-8f9fce9fc737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3173d8c7-0170-4f2f-a313-e3beff921beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11aecab-5b3a-450d-bddd-2390572a1f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c57d64-b7fd-4a92-8b8c-d431310ddd7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc2822-40fc-4f5e-957c-06b27a41a654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0e8aa-58cf-4a6c-8b40-9bd907f525e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f129932c-1a6e-47fb-807a-122411962648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
