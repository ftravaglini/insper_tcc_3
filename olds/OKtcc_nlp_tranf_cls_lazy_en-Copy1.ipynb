{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "791f0e12-bbb6-4bcb-8a2e-1048ab03bbd2",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a418dd8-90ca-41b5-b4ea-9638598d471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d116ad26-12a3-487c-9b47-5f9abe2b6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copom = pd.read_csv('df_copom_label_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60443267-16fc-4610-9633-d96d57c5a6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>meeting_number</th>\n",
       "      <th>date_x</th>\n",
       "      <th>date_y</th>\n",
       "      <th>selic</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_txt</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>num_words</th>\n",
       "      <th>text_raw</th>\n",
       "      <th>num_words_raw</th>\n",
       "      <th>label_hawk_dove</th>\n",
       "      <th>label_next_meet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>2006/03/08</td>\n",
       "      <td>2006/03/08</td>\n",
       "      <td>16.5</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>decrease</td>\n",
       "      <td>statement</td>\n",
       "      <td>march meeting , banco central brasil 's moneta...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>In the March Meeting, the Banco Central do Br...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>dovish</td>\n",
       "      <td>decrease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  meeting_number      date_x      date_y  selic  decision  \\\n",
       "0           0             117  2006/03/08  2006/03/08   16.5     -0.75   \n",
       "\n",
       "  decision_txt       type                                               text  \\\n",
       "0     decrease  statement  march meeting , banco central brasil 's moneta...   \n",
       "\n",
       "   num_words                                           text_raw  \\\n",
       "0       55.0   In the March Meeting, the Banco Central do Br...   \n",
       "\n",
       "   num_words_raw label_hawk_dove label_next_meet  \n",
       "0           67.0          dovish        decrease  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copom.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d382963-1e0d-46d5-814e-0ebf35898778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ = df_copom[(df_copom['type'] == 'statement')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c84c4022-78cd-4e0e-aa03-61e3ef9a1bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 14)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16f271df-2468-4004-b1db-62fbf73f010e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_words_ponct(text):\n",
    "    return len(re.findall(r'[^\\w\\s]|\\w+', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06462a79-971c-453c-a3f1-07bee3e74f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.loc[100,('num_words')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cca48ca6-0cc7-4aa2-8df0-61eff4ed7f41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words_ponct(df_.loc[100,('text')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c186003a-4d08-4902-a352-40f82b2785f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      march meeting , banco central brasil 's moneta...\n",
       "1      april meeting , monetary policy committee ( co...\n",
       "2      may meeting , monetary policy committee ( copo...\n",
       "3      july meeting , copom unanimously decided reduc...\n",
       "4      august meeting , copom unanimously decided red...\n",
       "                             ...                        \n",
       "154    250th meeting , copom decided maintain selic r...\n",
       "155    251st meeting , copom decided maintain selic r...\n",
       "158    252nd meeting , copom decided maintain selic r...\n",
       "160    since previous meeting monetary policy committ...\n",
       "162    global environment remains challenging . episo...\n",
       "Name: text, Length: 140, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b4be71a-8cdd-4d45-aba4-3826481264dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ftrav\\AppData\\Local\\Temp\\ipykernel_27004\\2047394345.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_['num_words_ponct'] = df_['text'].apply(count_words_ponct)\n"
     ]
    }
   ],
   "source": [
    "df_['num_words_ponct'] = df_['text'].apply(count_words_ponct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b93b77fa-034d-4f0c-a740-3cdf53112df7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       58\n",
       "1       37\n",
       "2       37\n",
       "3       32\n",
       "4       38\n",
       "      ... \n",
       "154    565\n",
       "155    581\n",
       "158    541\n",
       "160    494\n",
       "162    474\n",
       "Name: num_words_ponct, Length: 140, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_['num_words_ponct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae69da5f-51b0-43ac-b976-f08eb1fa40fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 58,  37,  32,  38,  33,  52,  80,  35,  56,  69,  68,  41,  39,\n",
       "        54,  55,  64,  42,  50,  74,  81,  72,  27,  79,  66,  85,  90,\n",
       "        65,  45,  46,  59,  96,  34,  88, 234,  57,  47,  73, 121, 125,\n",
       "       154,  61,  48, 162,  53,  36,  60,  40, 113, 123, 122, 256, 440,\n",
       "       521, 444, 477, 385, 438, 384, 398, 475, 466, 499, 463, 458, 531,\n",
       "       610, 616, 565, 618, 518, 530, 538, 557, 501, 515, 546, 579, 536,\n",
       "       485, 508, 609, 578, 602, 663, 657, 715, 576, 664, 552, 612, 240,\n",
       "       667, 511, 527, 525, 623, 690, 550, 581, 541, 494, 474], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_['num_words_ponct'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8e853d8-e066-46f9-bac5-f3686a143845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_[(df_['num_words_ponct'] <= 510)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28236cd9-58ad-4823-9eb0-78268227c7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 15)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4207fd03-91db-4c89-bacf-92cdbef7fc69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_['label_hawk_dove'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d3297e63-b26b-4cdc-8d8f-9cdfc2fb852e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       dovish\n",
       "1       dovish\n",
       "2       dovish\n",
       "3       dovish\n",
       "4       dovish\n",
       "        ...   \n",
       "154    neutral\n",
       "155    neutral\n",
       "158    neutral\n",
       "160    neutral\n",
       "162        NaN\n",
       "Name: label_hawk_dove, Length: 140, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_['label_hawk_dove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "84e19871-b405-48bf-a136-441609657027",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ftrav\\AppData\\Local\\Temp\\ipykernel_27004\\1136188436.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_['target'] = df_['label_hawk_dove'].map(target_map)\n"
     ]
    }
   ],
   "source": [
    "target_map = {'dovish': 0, 'hawkish': 1, 'neutral': 2}\n",
    "df_['target'] = df_['label_hawk_dove'].map(target_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e4eca18a-3e10-49b9-83c4-bb65cff671a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ = df_[df_['target'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b7900f11-59a3-4c9a-aae4-6b03255cf7fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_['target'] = df_['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f8074f75-ed79-455b-ab5b-cdba2f5c4f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8869383-6d9e-43fc-9b6c-fffcb62eb2e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_[['text', 'target']]\n",
    "df.columns = ['sentence', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b0ed66f4-e083-4527-8909-7a82316c0685",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>march meeting , banco central brasil 's moneta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>april meeting , monetary policy committee ( co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>may meeting , monetary policy committee ( copo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>july meeting , copom unanimously decided reduc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>august meeting , copom unanimously decided red...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0  march meeting , banco central brasil 's moneta...      0\n",
       "1  april meeting , monetary policy committee ( co...      0\n",
       "2  may meeting , monetary policy committee ( copo...      0\n",
       "3  july meeting , copom unanimously decided reduc...      0\n",
       "4  august meeting , copom unanimously decided red...      0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e0d2a3d6-ee93-439c-a618-efc6cc3f3cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('data_copom_transf_en.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90657d76-9557-498d-8653-ac7c404c7086",
   "metadata": {},
   "source": [
    "#### Convert to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "01d14340-a2e5-4f38-a2d3-dbbac8911a64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/ftrav/.cache/huggingface/datasets/csv/default-ae89f609a7c177ec/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "Extracting data files: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 142.90it/s]\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/ftrav/.cache/huggingface/datasets/csv/default-ae89f609a7c177ec/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 125.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_dataset = load_dataset('csv', data_files='data_copom_transf_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "516ab7be-ef65-4b11-a61c-4186da0bd307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 139\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c44e4b-0795-4f05-838d-c5caa6b9dcd9",
   "metadata": {},
   "source": [
    "#### Split test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "095e63a6-deb5-46d1-ac39-885c86bfe228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = raw_dataset['train'].train_test_split(test_size=0.3, seed=2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e2e58e4a-1f38-42f5-9ee4-ab40562b5c71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 97\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 42\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff51f9-f286-4f63-b42e-1ee6dc4ae8ca",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e2ac12f-92d4-4663-b0d8-fd758eb718fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"gtfintechlab/FOMC-RoBERTa\")\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"gtfintechlab/FOMC-RoBERTa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef2e55-00e0-4da5-9504-0024bfa0fc1a",
   "metadata": {},
   "source": [
    "@article{shah2023trillion, \n",
    "  title={Trillion Dollar Words: A New Financial Dataset, Task & Market Analysis},\n",
    "  author={Shah, Agam and Paturi, Suvan and Chava, Sudheer},\n",
    "  journal={Available at SSRN 4447632},\n",
    "  year={2023}\n",
    "}\n",
    "\n",
    "https://huggingface.co/gtfintechlab/FOMC-RoBERTa?text=Such+a+directive+would+imply+that+any+tightening+should+be+implemented+promptly+if+developments+were+perceived+as+pointing+to+rising+inflation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dd9153e5-deaa-414d-95d0-fe5fbe925dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'gtfintechlab/FOMC-RoBERTa'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be909174-068b-4879-89d1-2e1cd23d37b9",
   "metadata": {},
   "source": [
    "#### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "708d931c-f000-4bd0-a7d0-fd4745e1dc33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "abe79af4-de28-4046-b5c6-795283421950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, do_lower_case=True, truncation='longest_first') #, do_basic_tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3ffaf227-5f80-4f04-b016-ad0edf67e123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# truncation=\"only_first\" ensure that the beginning of the sentence is preserved\n",
    "# \"only_second\" keeps the end of the text\n",
    "# \"longest_first\" preserves as much text as possible from both ends\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['sentence'], truncation='longest_first') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ef275b04-2bdc-42b6-b977-232d93e56c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                              \r"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = split.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241abab3-3614-4325-925b-021aeafd7055",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "01320179-b486-4077-8a9f-16a1bd03f8a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "87f4ac5c-9ffe-4533-a89e-4a4d5b92f203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2e8488a3-a365-4db5-a400-e0a0699f0ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c06e7fac-7f9f-4c23-8cbc-ddb6eec92651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "RobertaForSequenceClassification                             --\n",
       "├─RobertaModel: 1-1                                          --\n",
       "│    └─RobertaEmbeddings: 2-1                                --\n",
       "│    │    └─Embedding: 3-1                                   51,471,360\n",
       "│    │    └─Embedding: 3-2                                   526,336\n",
       "│    │    └─Embedding: 3-3                                   1,024\n",
       "│    │    └─LayerNorm: 3-4                                   2,048\n",
       "│    │    └─Dropout: 3-5                                     --\n",
       "│    └─RobertaEncoder: 2-2                                   --\n",
       "│    │    └─ModuleList: 3-6                                  302,309,376\n",
       "├─RobertaClassificationHead: 1-2                             --\n",
       "│    └─Linear: 2-3                                           1,049,600\n",
       "│    └─Dropout: 2-4                                          --\n",
       "│    └─Linear: 2-5                                           3,075\n",
       "=====================================================================================\n",
       "Total params: 355,362,819\n",
       "Trainable params: 355,362,819\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3a0e98ae-ab04-42f9-aca1-5a49ad56e424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(logits_and_labels):\n",
    "    logits, labels = logits_and_labels\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = np.mean(predictions == labels)\n",
    "    f1 = f1_score(labels, predictions, average='macro')\n",
    "    return {'accuracy': acc, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "66ddafee-eacd-4637-a7b9-1304d9208585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='training_dir/en',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5c8a57c4-f80f-4347-a2b6-c87d433eb048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "39888059-a41b-41dc-b9ce-38c67d93ac56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ftrav\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 22:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.984999</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.546129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.101017</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.760439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.945483</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.806915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21, training_loss=1.0331297374906994, metrics={'train_runtime': 1399.1514, 'train_samples_per_second': 0.208, 'train_steps_per_second': 0.015, 'total_flos': 269547496156272.0, 'train_loss': 1.0331297374906994, 'epoch': 3.0})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e5c96c66-718f-4d6b-8b3d-6d81f8bb1a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 5AAA-7C2A\n",
      "\n",
      " Directory of C:\\Users\\ftrav\\Documents\\Insper_tcc\\training_dir\\en\n",
      "\n",
      "07/02/2023  11:46 AM    <DIR>          .\n",
      "07/01/2023  10:18 PM    <DIR>          ..\n",
      "07/01/2023  10:25 PM    <DIR>          checkpoint-10\n",
      "07/02/2023  11:38 AM    <DIR>          checkpoint-14\n",
      "07/01/2023  10:29 PM    <DIR>          checkpoint-15\n",
      "07/02/2023  11:46 AM    <DIR>          checkpoint-21\n",
      "07/01/2023  10:22 PM    <DIR>          checkpoint-5\n",
      "07/02/2023  11:19 AM    <DIR>          checkpoint-6\n",
      "07/02/2023  11:30 AM    <DIR>          checkpoint-7\n",
      "07/02/2023  11:22 AM    <DIR>          runs\n",
      "               0 File(s)              0 bytes\n",
      "              10 Dir(s)  66,278,060,032 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir training_dir\\en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e08da70f-72ae-436c-b0f3-041e326e2bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b68fad42-6f57-4eb5-aa31-9a36e0043199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "13f0bba8-b8e8-434a-a772-67cceef51075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "savedmodel = pipeline('text-classification',\n",
    "                      model='training_dir/en/checkpoint-21/',\n",
    "                      tokenizer=tokenizer, \n",
    "                      config=config,\n",
    "                      device=0,\n",
    "                      framework=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "715754d4-cd7d-4d61-975d-92ad49e71b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'label'],\n",
       "    num_rows: 42\n",
       "})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "003d484e-3062-48b2-b087-83196fae7d20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words_ponct(split['test']['sentence'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b2e43-d45b-4944-b2fa-d1b8791fdaf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb057f00-2873-4888-945a-55bd6c56faf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "134f8d15-6fe6-427b-a95d-0315be003fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (580) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 580].  Tensor sizes: [1, 514]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m savedmodel(split[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:155\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1098\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   1099\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1100\u001b[0m     )\n\u001b[1;32m-> 1101\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(final_iterator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\transformers\\pipelines\\base.py:1026\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1025\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1026\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1027\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:182\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_inputs):\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1509\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1510\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1216\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1216\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroberta(\n\u001b[0;32m   1217\u001b[0m     input_ids,\n\u001b[0;32m   1218\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1219\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   1220\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   1221\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1222\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1223\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1224\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1225\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1228\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1509\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1510\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcc_gpu2\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:818\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    817\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[1;32m--> 818\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m buffered_token_type_ids\u001b[38;5;241m.\u001b[39mexpand(batch_size, seq_length)\n\u001b[0;32m    819\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (580) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 580].  Tensor sizes: [1, 514]"
     ]
    }
   ],
   "source": [
    "test_pred = savedmodel(split['test']['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606dfa0-d709-4879-8217-709ca8e19a45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8537ea-5009-4a31-9467-123026384990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split['test']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddaa43f-06fb-46bf-9c9e-6f95d5cf785b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_label(d):\n",
    "    return int(d['label'].split('_')[1])\n",
    "\n",
    "test_pred = [get_label(d) for d in test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a50c0-69e6-440f-a849-f1cf91f032c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"acc:\", accuracy_score(split['test']['label'], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4447305-0e85-4267-a2ce-87867711658f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"f1:\", f1_score(split['test']['label'], test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c866b-ebf0-4da1-8fb7-4a652442c72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scikit-Learn is transitioning to V1 but it's not available on Colab\n",
    "# The changes modify how confusion matrices are plotted\n",
    "def plot_cm(cm):\n",
    "    classes = ['dovish', 'neutral', 'hawkish']\n",
    "    df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "    ax = sn.heatmap(df_cm, annot=True, fmt='g')\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Target\")\n",
    "\n",
    "cm = confusion_matrix(split['test']['label'], test_pred, normalize='true')\n",
    "plot_cm(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a645fc-0661-40d7-ae7b-0f9f04bc8286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa5334d4-7c04-4fdd-bea6-e1930d956aba",
   "metadata": {},
   "source": [
    "## gtfintechlab/FOMC-RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3173d8c7-0170-4f2f-a313-e3beff921beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gtfintechlab/FOMC-RoBERTa\", do_lower_case=True, do_basic_tokenize=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"gtfintechlab/FOMC-RoBERTa\", num_labels=3)\n",
    "config = AutoConfig.from_pretrained(\"gtfintechlab/FOMC-RoBERTa\")\n",
    "\n",
    "classifier = pipeline('text-classification', model=model, tokenizer=tokenizer, config=config, device=0, framework=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11aecab-5b3a-450d-bddd-2390572a1f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classifier([\"Such a directive would imply that any tightening should be implemented promptly if developments were perceived as pointing to rising inflation.\", \n",
    "                      \"The International Monetary Fund projects that global economic growth in 2019 will be the slowest since the financial crisis.\"], \n",
    "                      batch_size=128, truncation=\"only_first\")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c57d64-b7fd-4a92-8b8c-d431310ddd7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc2822-40fc-4f5e-957c-06b27a41a654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0e8aa-58cf-4a6c-8b40-9bd907f525e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f129932c-1a6e-47fb-807a-122411962648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
